{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8c4fae-e831-4b6a-acf0-51212da0dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eecd71c-0416-40e1-b08d-0f8f119c08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main dataset directory and subfolders\n",
    "main_folder = \"mydigits_dataset\"\n",
    "subfolders = ['1', '2', '3', '4']\n",
    "\n",
    "if not os.path.exists(main_folder):\n",
    "    os.makedirs(main_folder)\n",
    "\n",
    "# Create subfolders\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(main_folder, subfolder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86bfe4b-03e5-41b8-9d20-0f94d09c7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "arucoDict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_ARUCO_ORIGINAL)\n",
    "arucoParams = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(arucoDict,arucoParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3062e3-f51d-4253-b943-126df55195a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224,224\n",
    "\n",
    "def resize_frame(frame):\n",
    "    # Resize the frame to img_heightximg_width pixels\n",
    "    resized = cv2.resize(frame, (img_height, img_width))\n",
    "  \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c68d9b-6a77-41ec-92e8-473aec568b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture and save frames from video, with start/stop functionality\n",
    "def capture_and_save_frames_manual(folder_name):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    recording = False\n",
    "    frame_count = 0\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'r' to start recording, 's' to stop, and 'q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display the live feed\n",
    "        cv2.imshow('Camera', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('r'):  # Start recording\n",
    "            print(\"Recording started...\")\n",
    "            recording = True\n",
    "        \n",
    "        elif key == ord('s'):  # Stop recording\n",
    "            print(\"Recording stopped.\")\n",
    "            recording = False\n",
    "        \n",
    "        elif key == ord('q'):  # Quit the program\n",
    "            print(\"Quitting...\")\n",
    "            break\n",
    "\n",
    "        # If recording, save the frames to the folder\n",
    "        if recording:\n",
    "            (corners, ids, rejected) = detector.detectMarkers(frame)\n",
    "\n",
    "            m1_n=m2_n=m3_n=0\n",
    "            m1_xmin=m1_ymin=m2_xmin=m2_ymin=m3_xmin=m3_ymin=10000\n",
    "            m1_xmax=m1_ymax=m2_xmax=m2_ymax=m3_xmax=m3_ymax=0\n",
    "\n",
    "        \t# verify *at least* one ArUco marker was detected\n",
    "            if len(corners) > 0:\n",
    "        \t\t# flatten the ArUco IDs list\n",
    "                ids = ids.flatten()\n",
    "        \t\t# loop over the detected ArUCo corners\n",
    "                for (markerCorner, markerID) in zip(corners, ids):\n",
    "        \t\t\t# extract the marker corners (which are always returned\n",
    "        \t\t\t# in top-left, top-right, bottom-right, and bottom-left\n",
    "        \t\t\t# order)\n",
    "                    corners = markerCorner.reshape((4, 2))\n",
    "                    (topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "        \t\t\t# convert each of the (x, y)-coordinate pairs to integers\n",
    "                    topRight = (int(topRight[0]), int(topRight[1]))\n",
    "                    bottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "                    bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "                    topLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "\n",
    "        \t\t\t# NEW\n",
    "                    if markerID == 1:\n",
    "                        if bottomLeft[0]<m1_xmin:\n",
    "                           m1_xmin=bottomLeft[0]\n",
    "                        if bottomLeft[0]>m1_xmax:\n",
    "                           m1_xmax=bottomLeft[0]\n",
    "                        if bottomLeft[1]<m1_ymin:\n",
    "                           m1_ymin=bottomLeft[1]\n",
    "                        if bottomLeft[1]>m1_ymax:\n",
    "                           m1_ymax=bottomLeft[1]\n",
    "                        m1_n=m1_n+1\n",
    "\n",
    "                    if markerID == 2:\n",
    "                        if bottomLeft[0]<m2_xmin:\n",
    "                           m2_xmin=bottomLeft[0]\n",
    "                        if bottomLeft[0]>m2_xmax:\n",
    "                           m2_xmax=bottomLeft[0]\n",
    "                        if bottomLeft[1]<m2_ymin:\n",
    "                           m2_ymin=bottomLeft[1]\n",
    "                        if bottomLeft[1]>m2_ymax:\n",
    "                           m2_ymax=bottomLeft[1]\n",
    "                        m2_n=m2_n+1\n",
    "\n",
    "                    if markerID == 3:\n",
    "                        if bottomLeft[0]<m3_xmin:\n",
    "                           m3_xmin=bottomLeft[0]\n",
    "                        if bottomLeft[0]>m3_xmax:\n",
    "                           m3_xmax=bottomLeft[0]\n",
    "                        if bottomLeft[1]<m3_ymin:\n",
    "                           m3_ymin=bottomLeft[1]\n",
    "                        if bottomLeft[1]>m3_ymax:\n",
    "                           m3_ymax=bottomLeft[1]\n",
    "                        m3_n=m3_n+1\n",
    "\n",
    "                    rows,cols,ch = frame.shape\n",
    "\n",
    "                    if m1_n==4:\n",
    "                        dst=frame[m1_ymin:m1_ymax,m1_xmin:m1_xmax]\n",
    "        \t\t\t\t# cv2.imshow(\"unit√©s\",dst)\n",
    "                        frame_path = os.path.join(main_folder, folder_name, f\"frame_{frame_count}.png\")\n",
    "                        cv2.imwrite(frame_path, resize_frame(dst))\n",
    "                        frame_count += 1\n",
    "\n",
    "                    if m2_n==4:\n",
    "                        dst=frame[m2_ymin:m2_ymax,m2_xmin:m2_xmax]\n",
    "        \t\t\t\t# cv2.imshow(\"dizaines\",dst)\n",
    "                        frame_path = os.path.join(main_folder, folder_name, f\"frame_{frame_count}.png\")\n",
    "                        cv2.imwrite(frame_path, resize_frame(dst))\n",
    "                        frame_count += 1\n",
    "\n",
    "                    if m3_n==4:\n",
    "                        dst=frame[m3_ymin:m3_ymax,m3_xmin:m3_xmax]\n",
    "        \t\t\t\t# cv2.imshow(\"centaines\",dst)\n",
    "                        frame_path = os.path.join(main_folder, folder_name, f\"frame_{frame_count}.png\")\n",
    "                        cv2.imwrite(frame_path, resize_frame(dst))\n",
    "                        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caba07ac-2bba-4157-a6fa-0271d021bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'r' to start recording, 's' to stop, and 'q' to quit.\n",
      "Recording started...\n",
      "Recording stopped.\n",
      "Quitting...\n"
     ]
    }
   ],
   "source": [
    "capture_and_save_frames_manual('1')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17e8e4b0-94eb-40b8-8f6f-9dd99f7a0d7d",
   "metadata": {},
   "source": [
    "capture_and_save_frames_manual('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ae8a45-a376-4d7a-a785-5d22ad264d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'r' to start recording, 's' to stop, and 'q' to quit.\n",
      "Recording started...\n",
      "Recording started...\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Quitting...\n"
     ]
    }
   ],
   "source": [
    "capture_and_save_frames_manual('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "092ce7c0-03ab-498a-a2f1-bf706beb0fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'r' to start recording, 's' to stop, and 'q' to quit.\n",
      "Recording started...\n",
      "Recording started...\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Quitting...\n"
     ]
    }
   ],
   "source": [
    "capture_and_save_frames_manual('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82743c49-be54-49f6-9e10-900d0817ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'r' to start recording, 's' to stop, and 'q' to quit.\n",
      "Recording started...\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Recording stopped.\n",
      "Quitting...\n"
     ]
    }
   ],
   "source": [
    "capture_and_save_frames_manual('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad02a62-a537-4641-81eb-d8c6318314ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 19:25:19.140501: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-04 19:25:19.149235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738693519.160286   91390 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738693519.163645   91390 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-04 19:25:19.175264: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "367c4c85-4c9a-43dc-8ef0-ddc5d76090a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738693526.247160   91390 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1162 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained EfficientNetB0 without the top layers\n",
    "#base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Load pre-trained MobileNetV2 without the top layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for digit classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)  # Add dropout to prevent overfitting\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(4, activation='softmax')(x)  # For digits 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aa73942-af4c-4d8e-8694-4d9358a35930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81521d39-abce-4eb0-85e5-285087e7678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 images belonging to 4 classes.\n",
      "Found 125 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = 'mydigits_dataset'\n",
    "\n",
    "# Prepare the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path_to_dataset,  # Folder with subfolders 0-9\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    path_to_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "017e9741-b639-4f59-8bb2-b387f2e10b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc/KLIT/tf/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738693569.061488   97376 service.cc:148] XLA service 0x7c35800026d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738693569.061506   97376 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-02-04 19:26:09.120690: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738693569.494043   97376 cuda_dnn.cc:529] Loaded cuDNN version 90600\n",
      "E0000 00:00:1738693571.641352   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693571.753114   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693573.679048   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693573.769183   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/16\u001b[0m \u001b[32m‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m2:11\u001b[0m 9s/step - accuracy: 0.1875 - loss: 1.6990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738693575.258835   97376 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "E0000 00:00:1738693578.885224   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693578.975382   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.6040 - loss: 0.9223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 19:26:22.485219: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-02-04 19:26:22.626226: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181_0', 104 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "2025-02-04 19:26:22.735818: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2025-02-04 19:26:24.379570: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-02-04 19:26:24.515665: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181_0', 344 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2025-02-04 19:26:24.631063: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1181', 176 bytes spill stores, 176 bytes spill loads\n",
      "\n",
      "E0000 00:00:1738693586.116822   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693586.226040   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693587.986274   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1738693588.076315   97376 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 940ms/step - accuracy: 0.6159 - loss: 0.8972 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9675 - loss: 0.0878 - val_accuracy: 0.9920 - val_loss: 0.0223\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9889 - loss: 0.0348 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9995 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9970 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9963 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 7.9184e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9889 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 8.4991e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs  # Adjust based on your dataset size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('imagenet_digit_classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96a477e1-ba3e-4831-8053-8a43e0358a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "img_height, img_width = 224,224\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model(\"imagenet_digit_classifier.keras\")\n",
    "\n",
    "# Class labels corresponding to digits 1, 2, 3, and 4\n",
    "class_labels = [1, 2, 3, 4]\n",
    "\n",
    "# Function to preprocess the image before feeding into the model\n",
    "def preprocess_frame(frame):\n",
    "    # Convert the frame to grayscale\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize the frame to img_heightximg_width pixels\n",
    "    resized = cv2.resize(frame, (img_height, img_width))\n",
    "    \n",
    "    # Normalize the image (as your training data would have been normalized)\n",
    "    normalized = resized / 255.0\n",
    "    \n",
    "    # Reshape to match the input shape of your model (batch_size, height, width, channels)\n",
    "    reshaped = normalized.reshape(1, img_height, img_width, 3)\n",
    "    \n",
    "    return reshaped\n",
    "\n",
    "\n",
    "# Initialize camera capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    (corners, ids, rejected) = detector.detectMarkers(frame)\n",
    "    \n",
    "    m1_n=m2_n=m3_n=0\n",
    "    m1_xmin=m1_ymin=m2_xmin=m2_ymin=m3_xmin=m3_ymin=10000\n",
    "    m1_xmax=m1_ymax=m2_xmax=m2_ymax=m3_xmax=m3_ymax=0\n",
    "\n",
    "    # verify *at least* one ArUco marker was detected\n",
    "    if len(corners) >= 4:\n",
    "        # flatten the ArUco IDs list\n",
    "        ids = ids.flatten()\n",
    "        # loop over the detected ArUCo corners\n",
    "        for (markerCorner, markerID) in zip(corners, ids):\n",
    "            # extract the marker corners (which are always returned\n",
    "            # in top-left, top-right, bottom-right, and bottom-left\n",
    "            # order)\n",
    "            corners = markerCorner.reshape((4, 2))\n",
    "            (topLeft, topRight, bottomRight, bottomLeft) = corners\n",
    "            # convert each of the (x, y)-coordinate pairs to integers\n",
    "            topRight = (int(topRight[0]), int(topRight[1]))\n",
    "            bottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "            bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "            topLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "\n",
    "            # NEW\n",
    "            if markerID == 1:\n",
    "                if bottomLeft[0]<m1_xmin:\n",
    "                    m1_xmin=bottomLeft[0]\n",
    "                if bottomLeft[0]>m1_xmax:\n",
    "                    m1_xmax=bottomLeft[0]\n",
    "                if bottomLeft[1]<m1_ymin:\n",
    "                    m1_ymin=bottomLeft[1]\n",
    "                if bottomLeft[1]>m1_ymax:\n",
    "                    m1_ymax=bottomLeft[1]\n",
    "                m1_n=m1_n+1\n",
    "\n",
    "            if markerID == 2:\n",
    "                if bottomLeft[0]<m2_xmin:\n",
    "                    m2_xmin=bottomLeft[0]\n",
    "                if bottomLeft[0]>m2_xmax:\n",
    "                    m2_xmax=bottomLeft[0]\n",
    "                if bottomLeft[1]<m2_ymin:\n",
    "                    m2_ymin=bottomLeft[1]\n",
    "                if bottomLeft[1]>m2_ymax:\n",
    "                    m2_ymax=bottomLeft[1]\n",
    "                m2_n=m2_n+1\n",
    "\n",
    "            if markerID == 3:\n",
    "                if bottomLeft[0]<m3_xmin:\n",
    "                    m3_xmin=bottomLeft[0]\n",
    "                if bottomLeft[0]>m3_xmax:\n",
    "                    m3_xmax=bottomLeft[0]\n",
    "                if bottomLeft[1]<m3_ymin:\n",
    "                    m3_ymin=bottomLeft[1]\n",
    "                if bottomLeft[1]>m3_ymax:\n",
    "                    m3_ymax=bottomLeft[1]\n",
    "                m3_n=m3_n+1\n",
    "\n",
    "            \n",
    "            if m1_n==4:\n",
    "                dst=frame[m1_ymin:m1_ymax,m1_xmin:m1_xmax]\n",
    "                # Preprocess the frame for the model\n",
    "                processed_frame = preprocess_frame(dst)\n",
    "                # cv2.imshow(\"unit√©s\",dst)\n",
    "\n",
    "            if m2_n==4:\n",
    "                dst=frame[m2_ymin:m2_ymax,m2_xmin:m2_xmax]\n",
    "                # Preprocess the frame for the model                \n",
    "                processed_frame = preprocess_frame(dst)\n",
    "                # cv2.imshow(\"dizaines\",dst)\n",
    "\n",
    "            if m3_n==4:\n",
    "                dst=frame[m3_ymin:m3_ymax,m3_xmin:m3_xmax]\n",
    "                # Preprocess the frame for the model                \n",
    "                processed_frame = preprocess_frame(dst)\n",
    "                # cv2.imshow(\"centaines\",dst)\n",
    "\n",
    "            if m1_n==4 or m2_n==4 or m3_n==4:\n",
    "                # Perform inference\n",
    "                predictions = model.predict(processed_frame, verbose=0)\n",
    "    \n",
    "                # Get the probabilities for digits 1, 2, 3, 4\n",
    "                probabilities = predictions[0]  # Assuming your model outputs probabilities for 4 classes\n",
    "\n",
    "                # Find the index of the highest probability\n",
    "                max_index = np.argmax(probabilities)\n",
    "    \n",
    "                # Display the probabilities on the frame\n",
    "                for i, prob in enumerate(probabilities):\n",
    "                    text = f\"Digit {class_labels[i]}: {prob:.2f}\"\n",
    "        \n",
    "                    # Set text color: green for the highest probability, blue for others\n",
    "                    if i == max_index:\n",
    "                        color = (0, 255, 0)  # Green\n",
    "                    else:\n",
    "                        color = (255, 0, 0)  # Blue\n",
    "            \n",
    "                    cv2.putText(frame, text, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    # Show the frame with probabilities\n",
    "    cv2.imshow('Digit Prediction', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5a916-4081-4638-8e61-1aa2ba02312e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
